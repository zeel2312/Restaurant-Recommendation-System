{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca1f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in c:\\users\\zeelt\\appdata\\roaming\\python\\python38\\site-packages (1.1.2)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (2021.4.0)\n",
      "Requirement already satisfied: bleach>=3.1.1 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (3.3.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (7.6.3)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (4.59.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (5.8.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (1.2.4)\n",
      "Requirement already satisfied: parso>0.4.0 in c:\\program files\\anaconda\\lib\\site-packages (from swifter) (0.7.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\anaconda\\lib\\site-packages (from bleach>=3.1.1->swifter) (1.15.0)\n",
      "Requirement already satisfied: packaging in c:\\program files\\anaconda\\lib\\site-packages (from bleach>=3.1.1->swifter) (20.9)\n",
      "Requirement already satisfied: webencodings in c:\\program files\\anaconda\\lib\\site-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\program files\\anaconda\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\program files\\anaconda\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (5.4.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\program files\\anaconda\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.2.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\program files\\anaconda\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\program files\\anaconda\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.20.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (7.22.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\program files\\anaconda\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\program files\\anaconda\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\program files\\anaconda\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.3.4)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\program files\\anaconda\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.1.3)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\program files\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\program files\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.1.12)\n",
      "Requirement already satisfied: pickleshare in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: pygments in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (2.8.1)\n",
      "Requirement already satisfied: colorama in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (5.0.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (3.0.17)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.17.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\program files\\anaconda\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jupyter-core in c:\\program files\\anaconda\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (4.7.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\program files\\anaconda\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\program files\\anaconda\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\program files\\anaconda\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\program files\\anaconda\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (0.17.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\program files\\anaconda\\lib\\site-packages (from pandas>=1.0.0->swifter) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\program files\\anaconda\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.1)\n",
      "Requirement already satisfied: locket in c:\\program files\\anaconda\\lib\\site-packages\\locket-0.2.1-py3.8.egg (from partd>=0.3.10->dask[dataframe]>=2.10.0->swifter) (0.2.1)\n",
      "Requirement already satisfied: wcwidth in c:\\program files\\anaconda\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\program files\\anaconda\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (6.3.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\program files\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\program files\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.10.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\program files\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\program files\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.9.4)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.11.3)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\program files\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (20.0.0)\n",
      "Requirement already satisfied: nbconvert in c:\\program files\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (6.0.7)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\program files\\anaconda\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\program files\\anaconda\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\program files\\anaconda\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\program files\\anaconda\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.1.1)\n",
      "Requirement already satisfied: testpath in c:\\program files\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.4.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\program files\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\program files\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\program files\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\program files\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\program files\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.4.3)\n",
      "Requirement already satisfied: defusedxml in c:\\program files\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.7.1)\n",
      "Requirement already satisfied: async-generator in c:\\program files\\anaconda\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\program files\\anaconda\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\program files\\anaconda\\lib\\site-packages (from packaging->bleach>=3.1.1->swifter) (2.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\program files\\anaconda\\lib\\site-packages (1.20.1)\n",
      "Requirement already satisfied: nltk in c:\\program files\\anaconda\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\anaconda\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\program files\\anaconda\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\program files\\anaconda\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\program files\\anaconda\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: sklearn in c:\\users\\zeelt\\appdata\\roaming\\python\\python38\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\anaconda\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\program files\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\program files\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: arrow in c:\\users\\zeelt\\appdata\\roaming\\python\\python38\\site-packages (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\program files\\anaconda\\lib\\site-packages (from arrow) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.0->arrow) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install swifter --user\n",
    "!pip install numpy --user\n",
    "!pip install nltk --user\n",
    "!pip install sklearn --user\n",
    "!pip install arrow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1218acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "import gc\n",
    "import swifter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle \n",
    "import sys\n",
    "import arrow\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from multiprocessing import Pool\n",
    "import correct\n",
    "from correct import correct_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048655a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zeelt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zeelt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load nltk data\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6243d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = stopwords.words('english') # stop words\n",
    "lemmatizer = WordNetLemmatizer() # lemmatizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # tokenizer (lexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d475cae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FYWN1wneV18bWNgQjJ2GNg</td>\n",
       "      <td>\"Dental by Design\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"4855 E Warner Rd, Ste B9\"</td>\n",
       "      <td>Ahwatukee</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85044</td>\n",
       "      <td>33.330690</td>\n",
       "      <td>-111.978599</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Dentists;General Dentistry;Health &amp; Medical;Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He-G7vWjzVUysIKrfNbPUQ</td>\n",
       "      <td>\"Stephen Szabo Salon\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"3101 Washington Rd\"</td>\n",
       "      <td>McMurray</td>\n",
       "      <td>PA</td>\n",
       "      <td>15317</td>\n",
       "      <td>40.291685</td>\n",
       "      <td>-80.104900</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Hair Stylists;Hair Salons;Men's Hair Salons;Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KQPW8lFf1y5BT2MxiSZ3QA</td>\n",
       "      <td>\"Western Motor Vehicle\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"6025 N 27th Ave, Ste 1\"</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85017</td>\n",
       "      <td>33.524903</td>\n",
       "      <td>-112.115310</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Departments of Motor Vehicles;Public Services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8DShNS-LuFqpEWIp0HxijA</td>\n",
       "      <td>\"Sports Authority\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"5000 Arizona Mills Cr, Ste 435\"</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85282</td>\n",
       "      <td>33.383147</td>\n",
       "      <td>-111.964725</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Sporting Goods;Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PfOCPjBrlQAnz__NXj9h_w</td>\n",
       "      <td>\"Brick House Tavern + Tap\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"581 Howe Ave\"</td>\n",
       "      <td>Cuyahoga Falls</td>\n",
       "      <td>OH</td>\n",
       "      <td>44221</td>\n",
       "      <td>41.119535</td>\n",
       "      <td>-81.475690</td>\n",
       "      <td>3.5</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>American (New);Nightlife;Bars;Sandwiches;Ameri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                        name neighborhood  \\\n",
       "0  FYWN1wneV18bWNgQjJ2GNg          \"Dental by Design\"          NaN   \n",
       "1  He-G7vWjzVUysIKrfNbPUQ       \"Stephen Szabo Salon\"          NaN   \n",
       "2  KQPW8lFf1y5BT2MxiSZ3QA     \"Western Motor Vehicle\"          NaN   \n",
       "3  8DShNS-LuFqpEWIp0HxijA          \"Sports Authority\"          NaN   \n",
       "4  PfOCPjBrlQAnz__NXj9h_w  \"Brick House Tavern + Tap\"          NaN   \n",
       "\n",
       "                            address            city state postal_code  \\\n",
       "0        \"4855 E Warner Rd, Ste B9\"       Ahwatukee    AZ       85044   \n",
       "1              \"3101 Washington Rd\"        McMurray    PA       15317   \n",
       "2          \"6025 N 27th Ave, Ste 1\"         Phoenix    AZ       85017   \n",
       "3  \"5000 Arizona Mills Cr, Ste 435\"           Tempe    AZ       85282   \n",
       "4                    \"581 Howe Ave\"  Cuyahoga Falls    OH       44221   \n",
       "\n",
       "    latitude   longitude  stars  review_count  is_open  \\\n",
       "0  33.330690 -111.978599    4.0            22        1   \n",
       "1  40.291685  -80.104900    3.0            11        1   \n",
       "2  33.524903 -112.115310    1.5            18        1   \n",
       "3  33.383147 -111.964725    3.0             9        0   \n",
       "4  41.119535  -81.475690    3.5           116        1   \n",
       "\n",
       "                                          categories  \n",
       "0  Dentists;General Dentistry;Health & Medical;Or...  \n",
       "1  Hair Stylists;Hair Salons;Men's Hair Salons;Bl...  \n",
       "2  Departments of Motor Vehicles;Public Services ...  \n",
       "3                            Sporting Goods;Shopping  \n",
       "4  American (New);Nightlife;Bars;Sandwiches;Ameri...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "df_business = pd.read_csv('yelp_business.csv')\n",
    "df_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488519f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fNMVV_ZX7CJSDWQGdOM8Nw</td>\n",
       "      <td>\"Showmars Government Center\"</td>\n",
       "      <td>Uptown</td>\n",
       "      <td>\"600 E 4th St\"</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>28202</td>\n",
       "      <td>35.221647</td>\n",
       "      <td>-80.839345</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Restaurants;American (Traditional)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>c7X2SdKxVJMaOnFROO8WEg</td>\n",
       "      <td>\"Finga Lickin' Caribbean Eatery\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"2838 The Plz\"</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>28205</td>\n",
       "      <td>35.236823</td>\n",
       "      <td>-80.801084</td>\n",
       "      <td>4.5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Pizza;Food;Internet Cafes;Restaurants;Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>WUiDaFQRZ8wKYGLvmjFjAw</td>\n",
       "      <td>\"China Buffet\"</td>\n",
       "      <td>University City</td>\n",
       "      <td>\"8630 University Executive Park Dr\"</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>28262</td>\n",
       "      <td>35.306173</td>\n",
       "      <td>-80.752672</td>\n",
       "      <td>3.5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>Buffets;Restaurants;Sushi Bars;Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5q6Xh-UcJa78bp6dzyaE7w</td>\n",
       "      <td>\"Duck Donuts\"</td>\n",
       "      <td>Dilworth</td>\n",
       "      <td>\"1710 Kenilworth Ave, Ste 220\"</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>28203</td>\n",
       "      <td>35.202624</td>\n",
       "      <td>-80.844419</td>\n",
       "      <td>4.5</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "      <td>Breakfast &amp; Brunch;Food;Coffee &amp; Tea;Donuts;Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>bA21m-qbgN_GNR6g-AlfYw</td>\n",
       "      <td>\"Dynasty Buffett\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"2932 E Franklin Blvd\"</td>\n",
       "      <td>Gastonia</td>\n",
       "      <td>NC</td>\n",
       "      <td>28056</td>\n",
       "      <td>35.262735</td>\n",
       "      <td>-81.125895</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Restaurants;Chinese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                business_id                              name  \\\n",
       "14   fNMVV_ZX7CJSDWQGdOM8Nw      \"Showmars Government Center\"   \n",
       "103  c7X2SdKxVJMaOnFROO8WEg  \"Finga Lickin' Caribbean Eatery\"   \n",
       "126  WUiDaFQRZ8wKYGLvmjFjAw                    \"China Buffet\"   \n",
       "128  5q6Xh-UcJa78bp6dzyaE7w                     \"Duck Donuts\"   \n",
       "161  bA21m-qbgN_GNR6g-AlfYw                 \"Dynasty Buffett\"   \n",
       "\n",
       "        neighborhood                              address       city state  \\\n",
       "14            Uptown                       \"600 E 4th St\"  Charlotte    NC   \n",
       "103              NaN                       \"2838 The Plz\"  Charlotte    NC   \n",
       "126  University City  \"8630 University Executive Park Dr\"  Charlotte    NC   \n",
       "128         Dilworth       \"1710 Kenilworth Ave, Ste 220\"  Charlotte    NC   \n",
       "161              NaN               \"2932 E Franklin Blvd\"   Gastonia    NC   \n",
       "\n",
       "    postal_code   latitude  longitude  stars  review_count  is_open  \\\n",
       "14        28202  35.221647 -80.839345    3.5             7        1   \n",
       "103       28205  35.236823 -80.801084    4.5            21        1   \n",
       "126       28262  35.306173 -80.752672    3.5            76        1   \n",
       "128       28203  35.202624 -80.844419    4.5           373        1   \n",
       "161       28056  35.262735 -81.125895    3.5            30        1   \n",
       "\n",
       "                                            categories  \n",
       "14                  Restaurants;American (Traditional)  \n",
       "103    Pizza;Food;Internet Cafes;Restaurants;Caribbean  \n",
       "126             Buffets;Restaurants;Sushi Bars;Chinese  \n",
       "128  Breakfast & Brunch;Food;Coffee & Tea;Donuts;Re...  \n",
       "161                                Restaurants;Chinese  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business = df_business[df_business['categories'].notna() & df_business['state'].notna()]\n",
    "df_business_restaurants = df_business[df_business['categories'].str.contains('Restaurants') & df_business['state'].str.contains('NC|SC')] \n",
    "\n",
    "# delete df_business and call the garbage collector\n",
    "del(df_business)\n",
    "gc.collect()\n",
    "\n",
    "# leaving only open establishments (1 = open , 0 = closed)\n",
    "df_business_restaurants = df_business_restaurants[df_business_restaurants['is_open'] == 1]\n",
    "df_business_restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ac803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_restaurants.to_csv('df_business_restaurants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a363c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_business_restaurants.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ca0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word processing\n",
    "def text_preprocess(text):\n",
    "    text = tokenizer.tokenize(text.lower()) # we convert the text to lowercase and split it into tokens by spaces and punctuation marks\n",
    "    text = [re.sub('[^a-z\\s]', '', w) for w in text]# get rid of numbers and non-Latin characters\n",
    "    text = [lemmatizer.lemmatize(w) for w in text if w not in STOP_WORDS]# perform lemmatization and get rid of stop words\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdafb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25954e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada4a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5261668, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars                                               text  \n",
       "0      5  Super simple place but amazing nonetheless. It...  \n",
       "1      5  Small unassuming place that changes their menu...  \n",
       "2      5  Lester's is located in a beautiful neighborhoo...  \n",
       "3      4  Love coming here. Yes the place always needs t...  \n",
       "4      4  Had their chocolate almond croissant and it wa...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feedback data\n",
    "df_review = pd.read_csv(\"yelp_review.csv\")\n",
    "df_review = df_review.drop(['useful','funny','cool','date'],axis=1)\n",
    "# dataframe size\n",
    "print(df_review.shape)\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9561a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we leave only those reviews that relate to food establishments from the df_business_restaurants dataframe\n",
    "df_review = df_review[df_review['business_id'].isin(df_business_restaurants['business_id'])]\n",
    "# replace missing reviews with an empty string \n",
    "df_review[\"text\"].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b6fde48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f63633a3134306a4cc6ff25e2ec702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/183106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(183106, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effectively process the text using swifter and clear the received dataframe from reviews with empty text\n",
    "df_review['text'] = df_review['text'].swifter.apply(text_preprocess)\n",
    "df_review.shape # final dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "304d7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the resulting file without indexes\n",
    "df_review.to_csv('review_data_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f5fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(object):\n",
    "    \n",
    "    def __init__(self, U, I, learning_rate=0.1, lamda=0.1, num_epoches=5, num_batches=100):\n",
    "        self.learning_rate = learning_rate # learning rate\n",
    "        self.lamda = lamda # lambda for L2 regularization \n",
    "        self.num_epoches = num_epoches  # number of epochs\n",
    "        self.num_batches = num_batches  # number of batches\n",
    "        self.U = U # users feature matrix \n",
    "        self.I = I # items feature matrix\n",
    "        self.e = 0 # current epoch\n",
    "\n",
    "    # loss function\n",
    "    def loss(self, ratings):\n",
    "        errors = [(rat_ij - np.dot(self.U[i], self.I[j].T))**2 + self.lamda * \\\n",
    "              (norm(self.U[i]) + norm(self.I[j])) for i, j, rat_ij in ratings]\n",
    "        return sum(errors)\n",
    "\n",
    "    # updating U and I matrices with stochastic gradient descent\n",
    "    def update(self, ratings):\n",
    "        for i, j, rat_ij in ratings:\n",
    "            rat_ij_hat = np.dot(self.U[i], self.I[j].T)\n",
    "            grad_U_i = (rat_ij_hat - rat_ij) * self.I[j] + self.lamda * self.U[i]\n",
    "            grad_I_j = (rat_ij_hat - rat_ij) * self.U[i] + self.lamda * self.I[j]\n",
    "            self.U[i] -= self.learning_rate * grad_U_i\n",
    "            self.I[j] -= self.learning_rate * grad_I_j\n",
    "    \n",
    "    # model setup\n",
    "    def fit(self, train, test):\n",
    "        num_trains = train.shape[0] # number of training data\n",
    "        num_tests  = test.shape[0] # number of test data\n",
    "        while self.e < self.num_epoches:\n",
    "            self.e += 1\n",
    "            # shuffle training data\n",
    "            mixed_order = np.arange(num_trains)\n",
    "            np.random.shuffle(mixed_order)\n",
    "            avg_train_loss = [] # training data error \n",
    "            avg_test_loss  = [] # test data error\n",
    "            batch_size = int(num_trains / self.num_batches) # batch size\n",
    "            for batch in range(self.num_batches):\n",
    "                batch_indexes = np.arange(batch_size * batch, batch_size * (batch + 1))             \n",
    "                # select the current batch from the training data\n",
    "                current_batch_ratings = train[mixed_order[batch_indexes], :]\n",
    "                # sampling of random values from the test set with a size equal to the size of the training data batch\n",
    "                sample_test = test[np.random.choice(num_tests, batch_size), :]\n",
    "                # updating matrices U and I\n",
    "                self.update(current_batch_ratings)\n",
    "                # loss of training and test data\n",
    "                train_loss = self.loss(current_batch_ratings)\n",
    "                test_loss  = self.loss(sample_test)\n",
    "                avg_train_loss.append(train_loss)\n",
    "                avg_test_loss.append(test_loss)\n",
    "            \n",
    "            avg_train_loss = np.mean(avg_train_loss) / float(batch_size) # average error of training data\n",
    "            avg_test_loss  = np.mean(avg_test_loss) / float(batch_size) # mean error of test data\n",
    "            print(f'{arrow.now()} Epoch № {self.e}', file=sys.stderr)\n",
    "            print(f'{arrow.now()} Training loss:\\t{avg_train_loss}', file=sys.stderr)\n",
    "            print(f'{arrow.now()} Testing loss:\\t{avg_test_loss}', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ac4cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  \\\n",
      "0  WUz0DjjrEyWpHbMQOJe7gQ  3wB-JjsUjkvdNUDRnChsVg  yymNrvk1cioG5Bn5lWH2QQ   \n",
      "1  xbTDtqbo8MPvc2JazgoW9g  ewoVtCaCosO1dLqlPfuzNQ  sPwgafejYVdf8hd4-oDYVg   \n",
      "2  Gy55Wq_v5farLU8TyvVDlQ  ewoVtCaCosO1dLqlPfuzNQ  R1jJQi2yR44D_2ileqr8kA   \n",
      "3  LdmQZwe7h3tNycKy1cR_bg  ewoVtCaCosO1dLqlPfuzNQ  RcB7STNxoSDjtoK1pXgWBg   \n",
      "4  7fhTZf0zpRq9jsWneQ7IXA  ewoVtCaCosO1dLqlPfuzNQ  AuIiqDeL65kczmiFSkAWrA   \n",
      "\n",
      "   stars                                               text  \n",
      "0      2  busy night told u  minute wait ok problem went...  \n",
      "1      4  wing good great price love honey hot better wi...  \n",
      "2      5  came day life cant remember name ordered highl...  \n",
      "3      4  im pretty impressed food fab many flavor mood ...  \n",
      "4      4         best chain italian food spot charlotte far  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc8e958a89c4a6b8e20a25f0c14e6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/183106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61862194bb9f47a0a5fea34797c32dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/183106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: (146484, 4)\n",
      "Size of test data: (36622, 4)\n"
     ]
    }
   ],
   "source": [
    "# read csv file with processed data\n",
    "df_review = pd.read_csv(\"review_data_state.csv\")\n",
    "# replace missing reviews with an empty string \n",
    "df_review[\"text\"].fillna('', inplace=True)\n",
    "print(df_review.head())\n",
    "df_review = df_review[['user_id', 'business_id', 'stars', 'text']]\n",
    "# matching unique user ids to numeric values\n",
    "dict_users = {key: val for val, key in enumerate(df_review['user_id'].unique())}\n",
    "inv_dict_users = {val: key for key, val in dict_users.items()}\n",
    "# correspondence of unique id of establishments to numerical values\n",
    "dict_items = {key: val for val, key in enumerate(df_review['business_id'].unique())}\n",
    "inv_dict_items = {val: key for key, val in dict_items.items()}\n",
    "    \n",
    "df_review['user_id'] = df_review['user_id'].swifter.apply(lambda x: dict_users[x])\n",
    "df_review['business_id'] = df_review['business_id'].swifter.apply(lambda x: dict_items[x])\n",
    "    \n",
    "# separating the data into training and test\n",
    "train_ratings_df, test_ratings_df = train_test_split(df_review, test_size = 0.2)\n",
    "\n",
    "print(f'Size of training data: {train_ratings_df.shape}')\n",
    "print(f'Size of test data: {test_ratings_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65ff8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each user and institution, we combine all reviews into one paragraph\n",
    "def get_train_whole_text(df, name_id):\n",
    "    return df[[name_id,'text']].groupby(name_id).agg({'text': ' '.join})\n",
    "    \n",
    "    \n",
    "user_id_review_df = pd.DataFrame(index=inv_dict_users.keys(), columns=[\"text\"])\n",
    "user_id_review_df.index.name = 'user_id'\n",
    "business_id_review_df= pd.DataFrame(index=inv_dict_items.keys(), columns=[\"text\"])\n",
    "business_id_review_df.index.name = 'business_id'\n",
    "\n",
    "# tables store all users and establishments,\n",
    "# but only those recommendation texts that are relevant to the training data\n",
    "user_id_review_df['text'] =  get_train_whole_text(train_ratings_df, 'user_id')[\"text\"]\n",
    "business_id_review_df['text'] =  get_train_whole_text(train_ratings_df, 'business_id')[\"text\"]\n",
    "user_id_review_df[\"text\"].fillna('', inplace=True)\n",
    "business_id_review_df[\"text\"].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea1e3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features (feature extraction) from reviews using vectorization (TFIDF Vectorizer),\n",
    "# to use text to factorize a matrix\n",
    "business_id_vectorizer = TfidfVectorizer(tokenizer = tokenizer.tokenize, max_features=5000)\n",
    "business_id_vectors = business_id_vectorizer.fit_transform(business_id_review_df['text'])\n",
    "\n",
    "user_id_vectorizer = TfidfVectorizer(tokenizer = tokenizer.tokenize, max_features=5000)\n",
    "user_id_vectors = user_id_vectorizer.fit_transform(user_id_review_df['text'])\n",
    "\n",
    "# users-features matrix\n",
    "U = pd.DataFrame(user_id_vectors.toarray(), index=user_id_review_df.index, columns=user_id_vectorizer.get_feature_names())\n",
    "U.sort_index(inplace=True)\n",
    "# business-features matrix\n",
    "I = pd.DataFrame(business_id_vectors.toarray(), index=business_id_review_df.index, columns=business_id_vectorizer.get_feature_names())\n",
    "I.sort_index(inplace=True)\n",
    "\n",
    "matrixF = MatrixFactorization(U = U.to_numpy(), I = I.to_numpy(), learning_rate=0.07, lamda=0.1, num_epoches=8, num_batches=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e395af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>business_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3054</th>\n",
       "      <th>3055</th>\n",
       "      <th>3056</th>\n",
       "      <th>3057</th>\n",
       "      <th>3058</th>\n",
       "      <th>3059</th>\n",
       "      <th>3060</th>\n",
       "      <th>3061</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "business_id  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "user_id                                                                  ...   \n",
       "0             2.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1             NaN   4.0   5.0   4.0   4.0   5.0   NaN   NaN   NaN   NaN  ...   \n",
       "2             NaN   NaN   NaN   NaN   NaN   NaN   5.0   4.0   5.0   5.0  ...   \n",
       "3             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "business_id  3054  3055  3056  3057  3058  3059  3060  3061  3062  3063  \n",
       "user_id                                                                  \n",
       "0             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 3064 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = pd.pivot_table(df_review, values='stars', index=['user_id'], columns=['business_id'])\n",
    "R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "361acbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09T15:37:04.252557+05:30 Epoch № 1\n",
      "2022-04-09T15:37:04.252557+05:30 Training loss:\t1.9340961254977231\n",
      "2022-04-09T15:37:04.252557+05:30 Testing loss:\t7.736447450821662\n",
      "2022-04-09T15:37:18.770921+05:30 Epoch № 2\n",
      "2022-04-09T15:37:18.770921+05:30 Training loss:\t0.5912324921740809\n",
      "2022-04-09T15:37:18.770921+05:30 Testing loss:\t5.775119943535401\n",
      "2022-04-09T15:37:33.105427+05:30 Epoch № 3\n",
      "2022-04-09T15:37:33.105427+05:30 Training loss:\t0.5133931129322032\n",
      "2022-04-09T15:37:33.105427+05:30 Testing loss:\t5.600576459860597\n",
      "2022-04-09T15:37:47.081696+05:30 Epoch № 4\n",
      "2022-04-09T15:37:47.081696+05:30 Training loss:\t0.4956006462557998\n",
      "2022-04-09T15:37:47.081696+05:30 Testing loss:\t5.544917078507142\n",
      "2022-04-09T15:38:01.480089+05:30 Epoch № 5\n",
      "2022-04-09T15:38:01.480089+05:30 Training loss:\t0.48852420801572755\n",
      "2022-04-09T15:38:01.480089+05:30 Testing loss:\t5.546312753743678\n",
      "2022-04-09T15:38:15.647282+05:30 Epoch № 6\n",
      "2022-04-09T15:38:15.647282+05:30 Training loss:\t0.4841730638193551\n",
      "2022-04-09T15:38:15.647282+05:30 Testing loss:\t5.487053932807822\n",
      "2022-04-09T15:38:30.383734+05:30 Epoch № 7\n",
      "2022-04-09T15:38:30.383734+05:30 Training loss:\t0.48113874478316837\n",
      "2022-04-09T15:38:30.383734+05:30 Testing loss:\t5.511248647240925\n",
      "2022-04-09T15:38:47.693616+05:30 Epoch № 8\n",
      "2022-04-09T15:38:47.693616+05:30 Training loss:\t0.4786493565805202\n",
      "2022-04-09T15:38:47.693616+05:30 Testing loss:\t5.47346226307304\n"
     ]
    }
   ],
   "source": [
    "matrixF.fit(train_ratings_df.to_numpy()[:, 0:3], test_ratings_df.to_numpy()[:, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "860c9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = pd.DataFrame(matrixF.U, index=user_id_review_df.index, columns=user_id_vectorizer.get_feature_names())\n",
    "U.sort_index(inplace=True)\n",
    "I = pd.DataFrame(matrixF.I, index=business_id_review_df.index, columns=business_id_vectorizer.get_feature_names())\n",
    "I.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4c9a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    R = np.dot(matrixF.U, matrixF.I.T)\n",
    "    with Pool(processes = 10) as pool:\n",
    "        R = np.array(pool.map(correct_numbers, R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72f551bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted ratings\n",
    "R = pd.DataFrame(R, index=U.index, columns=I.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9a6bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted ratings:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>business_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3054</th>\n",
       "      <th>3055</th>\n",
       "      <th>3056</th>\n",
       "      <th>3057</th>\n",
       "      <th>3058</th>\n",
       "      <th>3059</th>\n",
       "      <th>3060</th>\n",
       "      <th>3061</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "business_id  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "user_id                                                                  ...   \n",
       "0               2     2     3     3     3     3     3     3     3     3  ...   \n",
       "1               3     4     5     4     4     5     4     4     4     4  ...   \n",
       "2               2     4     4     4     4     4     5     3     5     5  ...   \n",
       "3               2     3     4     3     3     3     3     3     3     4  ...   \n",
       "4               2     3     3     3     3     3     4     3     3     3  ...   \n",
       "\n",
       "business_id  3054  3055  3056  3057  3058  3059  3060  3061  3062  3063  \n",
       "user_id                                                                  \n",
       "0               1     2     2     1     2     3     1     1     1     1  \n",
       "1               2     3     2     2     2     4     1     1     2     2  \n",
       "2               2     3     2     2     2     3     1     1     2     2  \n",
       "3               1     2     2     1     2     3     1     1     1     1  \n",
       "4               1     2     2     1     2     3     1     1     1     1  \n",
       "\n",
       "[5 rows x 3064 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Predicted ratings:\\n\")\n",
    "R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e0119fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "place      0.538708\n",
       "good       0.499796\n",
       "pastry     0.462414\n",
       "love       0.448617\n",
       "food       0.435405\n",
       "brownie    0.430245\n",
       "great      0.417556\n",
       "caramel    0.406781\n",
       "salted     0.404390\n",
       "amelie     0.392790\n",
       "Name: 382, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 signs for the first institution\n",
    "I.iloc[train_ratings_df.iat[0, 1]].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b59c41d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.396725\n",
       "food       0.334373\n",
       "place      0.333249\n",
       "amelie     0.304033\n",
       "time       0.293293\n",
       "rooster    0.286795\n",
       "great      0.268817\n",
       "love       0.263502\n",
       "go         0.262274\n",
       "really     0.257570\n",
       "Name: 28480, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 signs for the first user\n",
    "U.iloc[train_ratings_df.iat[0, 0]].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a55525f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matrices U, I and vectorizer\n",
    "data = {'U': U, 'I': I, 'V': user_id_vectorizer}\n",
    "\n",
    "with open('recommendation_model.pkl', 'wb') as f:\n",
    "     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "314c0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the resulting file without indexes\n",
    "R.to_csv('predicted_ratings.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e44d83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'U':           ability      able  absolute  absolutely  abundance  abundant  \\\n",
      "user_id                                                                  \n",
      "0       -0.000096  0.014123  0.003683    0.037908   0.005368  0.001741   \n",
      "1        0.002981  0.012956  0.013881    0.068765   0.001744  0.001467   \n",
      "2        0.002659  0.036590  0.003817    0.026507  -0.000578  0.001176   \n",
      "3        0.000545  0.040091 -0.007044    0.056253   0.000749  0.000370   \n",
      "4       -0.002124  0.013286  0.016403    0.057184   0.000086  0.001189   \n",
      "...           ...       ...       ...         ...        ...       ...   \n",
      "61043   -0.002095  0.004766  0.004503    0.005273   0.000745  0.000459   \n",
      "61044    0.000114  0.006468  0.001033    0.008518   0.000857  0.000203   \n",
      "61045    0.000574  0.038484 -0.002430    0.099503   0.000433  0.005434   \n",
      "61046    0.001993  0.014268  0.003755    0.028980   0.003297  0.000539   \n",
      "61047    0.012789  0.014528  0.002598    0.029475   0.000987 -0.001217   \n",
      "\n",
      "               ac        accent    accept  acceptable  ...      zada  \\\n",
      "user_id                                                ...             \n",
      "0       -0.001094  9.295625e-03 -0.000858    0.002182  ...  0.014126   \n",
      "1        0.000942  5.979740e-04 -0.000234    0.005003  ...  0.002123   \n",
      "2       -0.000129 -3.934041e-05 -0.001199    0.000811  ...  0.001273   \n",
      "3       -0.000822 -1.380633e-03  0.001718    0.000559  ...  0.001981   \n",
      "4        0.002098  1.510923e-03  0.007327    0.005436  ... -0.001828   \n",
      "...           ...           ...       ...         ...  ...       ...   \n",
      "61043    0.000406 -1.098230e-07  0.000613    0.002740  ... -0.002089   \n",
      "61044    0.006984  7.356260e-03  0.000303    0.000794  ...  0.000690   \n",
      "61045    0.000243  5.529639e-03  0.002521    0.001647  ... -0.002144   \n",
      "61046    0.000606  5.494714e-03  0.002578    0.002410  ... -0.007972   \n",
      "61047    0.001939  1.215312e-03 -0.000469   -0.001591  ...  0.000507   \n",
      "\n",
      "            zaxby   zealand       zen      zero      zing      ziti       zoe  \\\n",
      "user_id                                                                         \n",
      "0       -0.000843 -0.000405  0.004454  0.008947 -0.000106 -0.000817  0.005234   \n",
      "1       -0.002288  0.000032 -0.001967  0.001545  0.000552  0.000257  0.003540   \n",
      "2       -0.002837 -0.001061 -0.001251  0.009475  0.001052  0.002134 -0.004467   \n",
      "3        0.001277 -0.006425  0.001816  0.009783 -0.000694 -0.002306 -0.000167   \n",
      "4        0.001357  0.002781  0.003506  0.002424  0.001925  0.000675  0.004431   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "61043    0.001640  0.000548  0.000226 -0.000077  0.001513 -0.000309 -0.002083   \n",
      "61044    0.000137 -0.000598 -0.000243  0.000380  0.000003  0.000262  0.000827   \n",
      "61045    0.000319 -0.000474  0.000813 -0.002275 -0.000497  0.017973  0.000283   \n",
      "61046    0.000395  0.000874  0.006527  0.003840  0.000511  0.001571  0.002737   \n",
      "61047   -0.002665  0.000755 -0.000282  0.010488  0.004698  0.000379 -0.009611   \n",
      "\n",
      "             zone  zucchini  \n",
      "user_id                      \n",
      "0       -0.000801 -0.000299  \n",
      "1        0.003027  0.029153  \n",
      "2       -0.000057  0.002509  \n",
      "3       -0.000369  0.029892  \n",
      "4        0.001721  0.000357  \n",
      "...           ...       ...  \n",
      "61043    0.001206  0.000303  \n",
      "61044    0.000020  0.000399  \n",
      "61045    0.001374  0.005657  \n",
      "61046    0.002942  0.007326  \n",
      "61047    0.001774  0.004129  \n",
      "\n",
      "[61048 rows x 5000 columns], 'I':               ability      able  absolute  absolutely  abundance  abundant  \\\n",
      "business_id                                                                  \n",
      "0            0.001551  0.077245 -0.003104    0.014926   0.001900 -0.000480   \n",
      "1           -0.003450  0.013144  0.030065    0.065485  -0.001150  0.003779   \n",
      "2            0.001259  0.019004  0.036538    0.114366   0.018818  0.000407   \n",
      "3            0.005722  0.055158  0.009323    0.147814   0.001962 -0.000062   \n",
      "4            0.000707  0.032069  0.048407    0.110625  -0.000396  0.011508   \n",
      "...               ...       ...       ...         ...        ...       ...   \n",
      "3059         0.011846  0.055813 -0.001208    0.259767   0.000237  0.000822   \n",
      "3060         0.000000  0.000000  0.000000    0.000000   0.000000  0.000000   \n",
      "3061         0.000082 -0.012205 -0.002389   -0.009803  -0.000159 -0.020918   \n",
      "3062         0.000308  0.004143 -0.000558    0.000974   0.000707  0.000197   \n",
      "3063         0.000456  0.003507  0.003205    0.018803  -0.000007 -0.000348   \n",
      "\n",
      "                   ac    accent    accept  acceptable  ...      zada  \\\n",
      "business_id                                            ...             \n",
      "0            0.002024  0.000423  0.000879    0.000013  ...  0.009321   \n",
      "1            0.000844 -0.000055  0.002327    0.002641  ... -0.024753   \n",
      "2            0.003643  0.000736  0.001166    0.003520  ...  0.002147   \n",
      "3           -0.002621  0.005292 -0.001366   -0.004001  ...  0.015208   \n",
      "4            0.002416  0.000804  0.005889   -0.001346  ...  0.012325   \n",
      "...               ...       ...       ...         ...  ...       ...   \n",
      "3059        -0.002182  0.001026  0.001611   -0.002413  ...  0.004159   \n",
      "3060         0.000000  0.000000  0.000000    0.000000  ...  0.000000   \n",
      "3061        -0.004249  0.000417  0.000343    0.000045  ... -0.000076   \n",
      "3062        -0.000676  0.001168  0.001382   -0.000867  ...  0.000150   \n",
      "3063        -0.000039  0.000179  0.000608    0.002544  ...  0.000061   \n",
      "\n",
      "                zaxby   zealand       zen      zero      zing      ziti  \\\n",
      "business_id                                                               \n",
      "0           -0.001955  0.008549  0.000897  0.014998 -0.001068  0.005604   \n",
      "1            0.000254 -0.007339 -0.011942  0.019218  0.010634 -0.000508   \n",
      "2            0.001728 -0.008978  0.018570  0.006815 -0.001282 -0.000529   \n",
      "3            0.006770  0.012737  0.016564 -0.000815  0.000858  0.010568   \n",
      "4            0.003443  0.002914  0.008988 -0.005072  0.007470  0.054157   \n",
      "...               ...       ...       ...       ...       ...       ...   \n",
      "3059         0.001895 -0.002017 -0.002041  0.021934  0.001077  0.004045   \n",
      "3060         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3061        -0.028886  0.000059 -0.000276  0.000426 -0.000229  0.000433   \n",
      "3062         0.000532 -0.000016 -0.000261 -0.001293  0.000244 -0.000123   \n",
      "3063         0.000151 -0.000055 -0.000043  0.002830  0.000128  0.000803   \n",
      "\n",
      "                  zoe      zone  zucchini  \n",
      "business_id                                \n",
      "0           -0.002588 -0.003376 -0.002028  \n",
      "1            0.023018 -0.003051  0.024449  \n",
      "2            0.005151  0.003464  0.033150  \n",
      "3           -0.002311  0.014262  0.039795  \n",
      "4            0.014502  0.002002  0.091154  \n",
      "...               ...       ...       ...  \n",
      "3059         0.002045  0.002398  0.001015  \n",
      "3060         0.000000  0.000000  0.000000  \n",
      "3061         0.000493 -0.000008  0.000644  \n",
      "3062         0.003755  0.002375  0.000477  \n",
      "3063         0.015755  0.000677  0.001572  \n",
      "\n",
      "[3064 rows x 5000 columns], 'V': TfidfVectorizer(max_features=5000,\n",
      "                tokenizer=<bound method RegexpTokenizer.tokenize of RegexpTokenizer(pattern='\\\\w+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL)>)}\n"
     ]
    }
   ],
   "source": [
    "# loading the saved model\n",
    "with open('recommendation_model.pkl', 'rb') as f:\n",
    "     model = pickle.load(f)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c32dc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = model[\"I\"]\n",
    "U = model[\"U\"]\n",
    "user_id_vectorizer = model[\"V\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07ab458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>3054</th>\n",
       "      <th>3055</th>\n",
       "      <th>3056</th>\n",
       "      <th>3057</th>\n",
       "      <th>3058</th>\n",
       "      <th>3059</th>\n",
       "      <th>3060</th>\n",
       "      <th>3061</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3065 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  0  1  2  3  4  5  6  7  8  ...  3054  3055  3056  3057  3058  \\\n",
       "0        0  2  2  3  3  3  3  3  3  3  ...     1     2     2     1     2   \n",
       "1        1  3  4  5  4  4  5  4  4  4  ...     2     3     2     2     2   \n",
       "2        2  2  4  4  4  4  4  5  3  5  ...     2     3     2     2     2   \n",
       "3        3  2  3  4  3  3  3  3  3  3  ...     1     2     2     1     2   \n",
       "4        4  2  3  3  3  3  3  4  3  3  ...     1     2     2     1     2   \n",
       "\n",
       "   3059  3060  3061  3062  3063  \n",
       "0     3     1     1     1     1  \n",
       "1     4     1     1     2     2  \n",
       "2     3     1     1     2     2  \n",
       "3     3     1     1     1     1  \n",
       "4     3     1     1     1     1  \n",
       "\n",
       "[5 rows x 3065 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = pd.read_csv('predicted_ratings.csv', sep='\\t')\n",
    "R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9a0dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What place are you looking for? Italian dinner with beautiful views and tasty wine\n",
      "\n",
      "№ 1\n",
      "Name: \"Fahrenheit\"\n",
      "City, state: Charlotte, NC\n",
      "Category: American (New);Pizza;Salad;Restaurants\n",
      "Average star: 3.0\n",
      "Review count: 523\n",
      "\n",
      "№ 2\n",
      "Name: \"Dilworth Tasting Room\"\n",
      "City, state: Charlotte, NC\n",
      "Category: Nightlife;Wineries;Restaurants;Bars;Wine Tasting Room;Food;Arts & Entertainment;Tapas/Small Plates;Wine Bars;Beer;Wine & Spirits;Modern European\n",
      "Average star: 4.5\n",
      "Review count: 77\n",
      "\n",
      "№ 3\n",
      "Name: \"Antico Italian Restaurant\"\n",
      "City, state: Huntersville, NC\n",
      "Category: Italian;Restaurants;Pizza;Seafood\n",
      "Average star: 4.5\n",
      "Review count: 83\n",
      "\n",
      "№ 4\n",
      "Name: \"Lake Norman Cottage\"\n",
      "City, state: Davidson, NC\n",
      "Category: Food;Beer;Wine & Spirits;Nightlife;Restaurants;Wine Bars;Bars;Tapas/Small Plates\n",
      "Average star: 4.0\n",
      "Review count: 25\n",
      "\n",
      "№ 5\n",
      "Name: \"Ferrucci's Old Tyme Italian Market\"\n",
      "City, state: Cornelius, NC\n",
      "Category: Italian;Delis;Meat Shops;Food;Restaurants;Caterers;Event Planning & Services;Grocery;Specialty Food\n",
      "Average star: 4.5\n",
      "Review count: 50\n"
     ]
    }
   ],
   "source": [
    "words = input(\"What place are you looking for? \")\n",
    "#words = \"Italian dinner with beautiful views and tasty wine\"\n",
    "\n",
    "\n",
    "query = pd.DataFrame([text_preprocess(words)], columns=['text']) # create a dataframe with a given query\n",
    "query_vector = user_id_vectorizer.transform(query['text']) # selection of query features\n",
    "query = pd.DataFrame(query_vector.toarray(), index=query.index, columns=user_id_vectorizer.get_feature_names())\n",
    "\n",
    "predictRating=pd.DataFrame(np.dot(query.loc[0],I.T), index=I.index, columns=['rating'])\n",
    "topRecommendations=pd.DataFrame.sort_values(predictRating,['rating'],ascending=[0])[:5]\n",
    "\n",
    "number = 0\n",
    "for i in topRecommendations.index:\n",
    "    number+=1\n",
    "    print(f\"\\n№ {number}\")\n",
    "    print(f\"Name: {df_business_restaurants[df_business_restaurants['business_id']==inv_dict_items[i]]['name'].iloc[0]}\")\n",
    "    print(f\"City, state: {df_business_restaurants[df_business_restaurants['business_id']==inv_dict_items[i]]['city'].iloc[0]}, {df_business_restaurants[df_business_restaurants['business_id']==inv_dict_items[i]]['state'].iloc[0]}\")\n",
    "    print(f\"Category: {df_business_restaurants[df_business_restaurants['business_id']==inv_dict_items[i]]['categories'].iloc[0]}\")\n",
    "    print(f\"Average star: {df_business_restaurants[df_business_restaurants['business_id']==inv_dict_items[i]]['stars'].iloc[0]}\")\n",
    "    print(f\"Review count: {df_business_restaurants[df_business_restaurants['business_id']==inv_dict_items[i]]['review_count'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c056ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
